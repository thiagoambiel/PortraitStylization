{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PortraitStylization_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I2frGXlB4IyA"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ANwZ4l769M"
      },
      "source": [
        "# PortraitStylization - Stylizing Human Portrait Images with Auxiliary Models.\n",
        "\n",
        "Welcome to the PortraitStylization demo notebook. Here you can find a simple way to interact with the project API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2frGXlB4IyA"
      },
      "source": [
        "## Install Dependecies and Load Modules\n",
        "\n",
        "Run it first to install the required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AGmbN0I0fDt"
      },
      "source": [
        "!git clone https://github.com/thiagoambiel/PortraitStylization.git\n",
        "%cd PortraitStylization/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZVxRc3Z7_fk"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PixbL_0YDxj1"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload\n",
        "\n",
        "import io\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image, ImageColor\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from ipywidgets import widgets, interact\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "from style_transfer import StyleTransfer\n",
        "from remove_bg import BackgroundRemoval\n",
        "\n",
        "\n",
        "class ImageUploader:\n",
        "  def __init__(self, only_one: bool = False):\n",
        "    self.only_one = only_one\n",
        "    self.data = []\n",
        "\n",
        "    self.output = widgets.Output()\n",
        "    self.uploader = widgets.FileUpload(multiple=not self.only_one)\n",
        "\n",
        "\n",
        "  def plot_images(self):    \n",
        "    f, axarr = plt.subplots(1, len(self.data), figsize=(4 * len(self.data), 4 * len(self.data)))\n",
        "\n",
        "    if len(self.data) > 1:\n",
        "      for idx, img in enumerate(self.data):\n",
        "        axarr[idx].imshow(img)\n",
        "\n",
        "    else:\n",
        "      axarr.imshow(self.data[0])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  def save(self, _):\n",
        "    with self.output:\n",
        "\n",
        "      if self.only_one and len(self.data) > 0:\n",
        "        raise ValueError(\"Only one image can be uploaded in this field.\")\n",
        "\n",
        "      for name, file_info in self.uploader.value.items():\n",
        "        img = Image.open(io.BytesIO(file_info['content']))\n",
        "        self.data.append(img)\n",
        "\n",
        "      self.output.clear_output(wait=True)\n",
        "\n",
        "      print(\"Image Uploaded!\")\n",
        "      self.plot_images()\n",
        "\n",
        "\n",
        "  def run(self):\n",
        "    display(self.output, self.uploader)\n",
        "    self.uploader.observe(self.save, names='_counter')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I_J5tpi4OyB"
      },
      "source": [
        "# Let's Setup our Model\n",
        "\n",
        "Upload your Content and Style Images, Configure the Model Parameters and Run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luz6tA-kHFKp"
      },
      "source": [
        "#@title Upload Content Image {display-mode: \"form\"}\n",
        "#@markdown Upload a Content Image to be Stylized.\n",
        "\n",
        "content_uploader = ImageUploader(only_one=True)\n",
        "content_uploader.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTeeSRwjIpqR"
      },
      "source": [
        "#@title Upload Style Images {display-mode: \"form\"}\n",
        "#@markdown Upload the style images that will be used to stylize the content.\n",
        "#@markdown You can upload more than one image.\n",
        "\n",
        "styles_uploader = ImageUploader()\n",
        "styles_uploader.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiPRPk7BV42A",
        "cellView": "form"
      },
      "source": [
        "#@title Preprocess Content and Style Data { run: \"auto\" }\n",
        "#@markdown For some images, it is recommended to remove the background for better results. use 'MODNet' to load the background removal tool or 'Raw_Content' to use the original image as input.\n",
        "\n",
        "Mode = \"MODNet\" #@param ['MODNet', 'Raw_Content']\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "original_image = content_uploader.data[0]\n",
        "style_images = styles_uploader.data\n",
        "\n",
        "def render(bgcolor, fgcolor, fg_fac, bt_fac, upload):\n",
        "\n",
        "    texture_img = None\n",
        "    if upload.items():\n",
        "      name, file_info = next(iter(upload.items()))\n",
        "      texture_img = Image.open(io.BytesIO(file_info['content']))\n",
        "      print(f\"Texture Loaded: {name}\")\n",
        "\n",
        "    result = background_removal.remove_background(\n",
        "        img=original_image,\n",
        "        alpha=alpha,\n",
        "        bg_color=bgcolor,\n",
        "        bg_texture=texture_img,\n",
        "        bt_fac=bt_fac,\n",
        "        fg_color=fgcolor,\n",
        "        fg_fac=fg_fac\n",
        "    )\n",
        "\n",
        "    f, axarr = plt.subplots(1, 3, figsize=(9, 3))\n",
        "\n",
        "    axarr[0].imshow(original_image)\n",
        "    axarr[1].imshow(alpha)\n",
        "    axarr[2].imshow(result)\n",
        "\n",
        "    result_data.clear()\n",
        "    result_data.insert(0, result)\n",
        "    \n",
        "    return f.tight_layout()\n",
        "\n",
        "\n",
        "if Mode == \"MODNet\":\n",
        "\n",
        "  background_removal = BackgroundRemoval(weights_path=\"./weights/modnet.pth\", device=device)\n",
        "  alpha = background_removal.gen_alpha(np.array(original_image))\n",
        "\n",
        "  bgcolor_picker = widgets.ColorPicker(description='Back', value='#4911e4')\n",
        "  fgcolor_picker = widgets.ColorPicker(description='Fore', value='#ffffff')\n",
        "  fg_fac_slider = widgets.FloatSlider(description='ForeFac', value=0.0, min=0, max=1.0, step=0.05)\n",
        "  bt_fac_slider = widgets.FloatSlider(description='TextureFac', value=1.0, min=0, max=1.0, step=0.05)\n",
        "\n",
        "  texture_uploader = widgets.FileUpload(description=\"Load Texture\")\n",
        "  texture_uploader.add_class(\"left-spacing-class\")\n",
        "  display(HTML(\n",
        "     \"\"\"<style>.left-spacing-class {\n",
        "       margin-left: 120px;\n",
        "       margin-bottom: 20px;\n",
        "       margin-top: 10px;\n",
        "       }\n",
        "     </style>\"\"\"\n",
        "  ))\n",
        "\n",
        "  result_data = []\n",
        "\n",
        "  interact(render, \n",
        "    bgcolor=bgcolor_picker, \n",
        "    fgcolor=fgcolor_picker, \n",
        "    fg_fac=fg_fac_slider, \n",
        "    bt_fac=bt_fac_slider, \n",
        "    upload=texture_uploader\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu3H6fXvdobs",
        "cellView": "form"
      },
      "source": [
        "#@title Set Algorithm Parameters and Run\n",
        "\n",
        "content_image = result_data[0] if Mode == \"MODNet\" else original_image\n",
        "\n",
        "#@markdown Adjust Weights for Better Results.\n",
        "content_weight = 0.015 #@param {type: \"number\"}\n",
        "face_weight = 0.015 #@param {type: \"number\"}\n",
        "mesh_weight =  0#@param {type: \"number\"}\n",
        "\n",
        "#@markdown Select the Initial and Final Resolution of your Stylized Image.\n",
        "min_scale = 128 #@param {type: \"number\"}\n",
        "end_scale =  1448#@param {type: \"number\"}\n",
        "\n",
        "#@markdown Set the Number of Iterations per Scale.\n",
        "iterations =  1000#@param {type: \"number\"}\n",
        "initial_iterations = 1000 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown The Relative Scale of the Style to the Content.\n",
        "style_scale_fac = 1 #@param {type: \"slider\", min: 0.0, max: 2.0, step: 0.1}\n",
        "\n",
        "#@markdown Enable Face Cropping when passing data to FaceNet and FaceMesh.\n",
        "crop_faces = False #@param {type:\"boolean\"}\n",
        "square_faces = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Add Padding to the Detected Faces Bounding Boxes (Need crop_faces to be Enabled).\n",
        "padding_scale_fac = 0 #@param {type: \"slider\", min: 0.0, max: 1.0, step: 0.1}\n",
        "\n",
        "#@markdown Set VGG Layers Pooling type.\n",
        "pooling = \"max\" #@param ['max', 'average', 'l2']\n",
        "\n",
        "st = StyleTransfer(device=device, pooling=pooling)\n",
        "\n",
        "st.stylize(\n",
        "  content_image=content_image, style_images=style_images,\n",
        "\n",
        "  content_weight=content_weight,\n",
        "  face_weight=face_weight,\n",
        "  mesh_weight=mesh_weight,\n",
        "\n",
        "  min_scale=min_scale,\n",
        "  end_scale=end_scale,\n",
        "\n",
        "  iterations=iterations,\n",
        "  initial_iterations=initial_iterations,\n",
        "\n",
        "  style_scale_fac=style_scale_fac,\n",
        "\n",
        "  crop_faces=crop_faces,\n",
        "  square_faces=square_faces,\n",
        "\n",
        "  padding_scale_fac=padding_scale_fac,\n",
        "\n",
        "  plot_progress=True,\n",
        "  save_path=\"/content/result.png\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}